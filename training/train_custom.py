# -*- coding: utf-8 -*-
"""Another copy of train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xdun9EBX2zXW5NMH3g3F6epIx_q2RNfK

# **Person & License Plate Blurring**
### **Embodied Intelligence ‚Äî ELTE Budapest**
**Fall Semester 2025**

**Authors:**  
- **Hadj Sassi Emen**  
- **Noah van Potten**

---

This notebook demonstrates how to train a YOLOv5-based detection system for **automatically identifying and blurring people and license plates** in images or video streams.  
The project is developed as part of the **Embodied Intelligence** course at **ELTE Budapest**, Fall 2025.

## üß† **Project Overview**

We designed a detection pipeline capable of identifying:

- **Humans**
- **License plates**

Once detected, the regions can be **blurred**.

The system uses:

- **YOLOv5** for object detection  
- **A custom dataset** exported via Roboflow  
- **On-the-fly dataset refactoring** to conform to YOLOv5's structure  

This notebook contains:

1. Dataset download  
2. Automatic dataset cleanup (Roboflow ‚Üí YOLOv5 fix)  
3. Training the YOLOv5 model  
4. Running inference on test images  
5. Producing anonymized output
"""

"""
Install the dependencies for this project.
"""

import contextlib
# Clone YOLOv5 package
!git clone https://github.com/ultralytics/yolov5.git --quiet
print("YOLOv5 installed succesfully!")

# Install YOLOv5 package dependencies
!pip install -r yolov5/requirements.txt --quiet
print("YOLOv5 package dependecies installed succesfully!")

# Install roboflow package
!pip install roboflow --quiet
print("Roboflow installed succesfully!")

"""
Download the custom dataset from Roboflow
"""

# Import roboflow
from roboflow import Roboflow

# Instantiate the Roboflow wrapper class with your API key
rf = Roboflow(api_key="DA1VlRYxFoKlQWOv8V2b")

# Load the correct workspace and project from your dataset URL
project = rf.workspace("t-ag3gh").project("yolo_model-x5ux3-zilgv")

# Specify project version
version = project.version(1)

# Download the dataset in YOLOv5 format
dataset = version.download("yolov5")

print("\nDataset downloaded successfully!")

import os, yaml, glob

dataset_path = dataset.location.rstrip("/")
yaml_path = f"{dataset_path}/data.yaml"

clean_yaml = {
    "path": dataset_path,
    "train": "train/images",
    "val": "valid/images",
    "test": "test/images",
    "nc": 2,
    "names": ["Human", "LicensePlate"],
}

with open(yaml_path, "w") as f:
    yaml.dump(clean_yaml, f)

# Fix label folders
splits = ["train", "valid", "test"]
for s in splits:
    old = f"{dataset_path}/{s}/labelTxt"
    new = f"{dataset_path}/{s}/labels"
    if os.path.exists(old):
        os.rename(old, new)

print("‚úî Data.yaml cleaned and folder structure fixed")

import subprocess, sys, shutil

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
os.environ["WANDB_DISABLED"] = "true"

def run_training(cfg, run_name):
    """Train YOLOv5 with clean single-line logging."""
    cmd = [
        "python", "/content/yolov5/train.py",
        "--data", yaml_path,
        "--weights", "yolov5s.pt",
        "--img", str(cfg["img"]),
        "--batch", str(cfg["batch"]),
        "--epochs", str(cfg["epochs"]),
        "--project", "/content/yolov5/runs/train",
        "--name", run_name,
        "--exist-ok",
    ]

    if cfg.get("optimizer") == "Adam":
        cmd += ["--optimizer", "Adam"]

    if cfg.get("iou"):
        cmd += ["--iou_t", str(cfg["iou"])]

    if cfg.get("strong_aug"):
        cmd += [
            "--hsv_h", "0.015",
            "--hsv_s", "0.7",
            "--hsv_v", "0.7",
            "--degrees", "10",
            "--translate", "0.2",
            "--scale", "0.7",
        ]

    print(f"\nüöÄ Starting Experiment: {run_name}")
    print(f"Settings: {cfg}\n")

    process = subprocess.Popen(
        cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
        text=True, bufsize=1
    )

    for raw in process.stdout:
        line = raw.strip()
        if "Epoch" in line or "%" in line:
            sys.stdout.write("\r" + line)
            sys.stdout.flush()

    process.wait()
    print("\n‚úî Training complete:", run_name)

    # ZIP results for convenience
    run_dir = f"/content/yolov5/runs/train/{run_name}"
    zip_path = f"/content/{run_name}.zip"
    shutil.make_archive(f"/content/{run_name}", "zip", run_dir)

    print(f" Exported ZIP ‚Üí {zip_path}")

" DEFINE HYPERPARAMETER SEARCH SPACE"

search_space = [
    {"epochs": 70, "img": 768, "batch": 16},                         # bigger img ‚Üí recall
    {"epochs": 70, "img": 640, "batch": 16, "optimizer": "Adam"},    # Adam ‚Üí better convergence
    {"epochs": 70, "img": 640, "batch": 32, "optimizer": "Adam"},    # try larger batch once
]

" RUN ALL EXPERIMENTS"

for i, cfg in enumerate(search_space):
    run_name = f"recall_search_exp_{i}"
    run_training(cfg, run_name)

print("\nüéâ ALL EXPERIMENTS COMPLETED!")
print("Check: /content/yolov5/runs/train/")

import pandas as pd

data = {
    "Model": ["Model 2", "Model 1", "Model 4", "Model 3"],
    "Hyperparameters": [
        '{"epochs": 70, "img": 768, "batch": 16}',
        '{"epochs": 50, "img": 640, "batch": 16}',
        '{"epochs": 70, "img": 640, "batch": 32, "optimizer": "Adam"}',
        '{"epochs": 70, "img": 640, "batch": 16, "optimizer": "Adam"}',
    ],
    "Precision": [0.84002, 0.76466, 0.75382, 0.67740],
    "Recall": [0.69784, 0.61957, 0.58452, 0.49079],
    "mAP@0.5": [0.76475, 0.66247, 0.62648, 0.53567],
    "mAP@0.5:0.95": [0.42989, 0.33206, 0.29565, 0.25409],
    "Rank": ["ü•á Best", "ü•à", "ü•â", "‚ùå Worst"]
}

df = pd.DataFrame(data)
df

table = """
| Model       | Hyperparameters                                                | Precision   | Recall      | mAP@0.5     | mAP@0.5:0.95 | Rank        |
|-------------|----------------------------------------------------------------|-------------|-------------|-------------|---------------|-------------|
| **Model 2** | `{"epochs": 70, "img": 768, "batch": 16}`                      | **0.84002** | **0.69784** | **0.76475** | **0.42989**  | ü•á **Best** |
| Model 1     | `{"epochs": 50, "img": 640, "batch": 16}`                      | 0.76466     | 0.61957     | 0.66247     | 0.33206      | ü•à          |
| Model 4     | `{"epochs": 70, "img": 640, "batch": 32, "optimizer": "Adam"}` | 0.75382     | 0.58452     | 0.62648     | 0.29565      | ü•â          |
| Model 3     | `{"epochs": 70, "img": 640, "batch": 16, "optimizer": "Adam"}` | 0.67740     | 0.49079     | 0.53567     | 0.25409      | ‚ùå Worst     |
"""

print(table)

import pandas as pd

df = pd.DataFrame({
    "Model": ["Model 2", "Model 1", "Model 4", "Model 3"],
    "Hyperparameters": [
        '{"epochs": 70, "img": 768, "batch": 16}',
        '{"epochs": 50, "img": 640, "batch": 16}',
        '{"epochs": 70, "img": 640, "batch": 32, "optimizer": "Adam"}',
        '{"epochs": 70, "img": 640, "batch": 16, "optimizer": "Adam"}',
    ],
    "Precision": [0.84002, 0.76466, 0.75382, 0.67740],
    "Recall": [0.69784, 0.61957, 0.58452, 0.49079],
    "mAP@0.5": [0.76475, 0.66247, 0.62648, 0.53567],
    "mAP@0.5:0.95": [0.42989, 0.33206, 0.29565, 0.25409],
    "Rank": ["ü•á Best", "ü•à", "ü•â", "‚ùå Worst"]
})

markdown_table = df.to_markdown(index=False)
print(markdown_table)

